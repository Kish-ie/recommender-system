{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "12oomObemT2qKm8QUZGkEIw5dc05laLJs",
      "authorship_tag": "ABX9TyOV0mH+o/2IbL1PGQeSOrFV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kish-ie/recommender-system/blob/main/recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U82VrctuEN18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTu4zSm46V9g",
        "outputId": "821bde21-870c-47be-d798-abc9ef443c9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Id   ProductId          UserId                      ProfileName  \\\n",
            "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
            "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
            "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
            "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
            "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
            "\n",
            "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
            "0                     1                       1      5  1303862400   \n",
            "1                     0                       0      1  1346976000   \n",
            "2                     1                       1      4  1219017600   \n",
            "3                     3                       3      2  1307923200   \n",
            "4                     0                       0      5  1350777600   \n",
            "\n",
            "                 Summary                                               Text  \n",
            "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
            "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
            "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
            "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
            "4            Great taffy  Great taffy at a great price.  There was a wid...  \n",
            "Model saved to recommendation_model.pkl\n",
            "Top recommendations for user A3SGXH7AUHU8GW:\n",
            "1. Product ID: B0032RPLSY, Predicted Rating: 5.00\n",
            "   Summary: Simply delicious flavor!\n",
            "   Text: I have been using butter ghee for cooking purposes, and found this product on Amazon.  The color is ...\n",
            "\n",
            "2. Product ID: B005EL6VOY, Predicted Rating: 5.00\n",
            "   Summary: Tasty and healthy!!\n",
            "   Text: My husband and I love Coach's Oats.  We first tried them on recommendation by a friend.  They are ki...\n",
            "\n",
            "3. Product ID: B0007UQ73W, Predicted Rating: 5.00\n",
            "   Summary: Staple item in my pantry\n",
            "   Text: I am a professional chef and work on mega yachts all around the world. This is one of the finest aut...\n",
            "\n",
            "4. Product ID: B000Q0IMOK, Predicted Rating: 5.00\n",
            "   Summary: Quality Product...good value\n",
            "   Text: This Chocolate can be found at Dean & DeLuca at twice the price.<br />The packaging is a plain plast...\n",
            "\n",
            "5. Product ID: B00401OZ1U, Predicted Rating: 5.00\n",
            "   Summary: Great pure taste\n",
            "   Text: No sugary junk here. Pure water and mint, nothing else, SPLENDID! If you are used to drinking sodas ...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from surprise import Dataset, Reader, SVD\n",
        "from surprise.model_selection import train_test_split\n",
        "import joblib  # For saving the model\n",
        "\n",
        "\n",
        "# Fix CSV file\n",
        "def fix_csv(file_path, output_path):\n",
        "    with open(file_path, 'r') as infile, open(output_path, 'w') as outfile:\n",
        "        for line in infile:\n",
        "            # Fix unclosed quotes (example logic)\n",
        "            if line.count('\"') % 2 != 0:  # Check if quotes are unbalanced\n",
        "                line = line.replace('\\n', '\"\\n')  # Close the quote\n",
        "            outfile.write(line)\n",
        "\n",
        "\n",
        "# Load dataset\n",
        "def load_data(file_path):\n",
        "    df = pd.read_csv(file_path, on_bad_lines='skip')  # Skip problematic rows\n",
        "    print(df.head())  # Inspect the dataset\n",
        "    return df\n",
        "\n",
        "\n",
        "# Prepare data for Surprise library\n",
        "def prepare_data(df):\n",
        "    reader = Reader(rating_scale=(1, 5))  # Adjust the rating scale if needed\n",
        "    data = Dataset.load_from_df(df[['UserId', 'ProductId', 'Score']], reader)\n",
        "    return data\n",
        "\n",
        "\n",
        "# Train and save the model\n",
        "def train_and_save_model(data, model_path='model.pkl'):\n",
        "    trainset, _ = train_test_split(data, test_size=0.2)\n",
        "    model = SVD()  # Singular Value Decomposition (SVD)\n",
        "    model.fit(trainset)\n",
        "\n",
        "    # Save the model to disk\n",
        "    joblib.dump(model, model_path)\n",
        "    print(f\"Model saved to {model_path}\")\n",
        "    return model\n",
        "\n",
        "\n",
        "# Recommend products for a user\n",
        "def recommend_products(model, user_id, df, num_recommendations=5):\n",
        "    # Get all unique products\n",
        "    unique_products = df['ProductId'].unique()\n",
        "\n",
        "    # Get products already rated by the user\n",
        "    user_rated_products = df[df['UserId'] == user_id]['ProductId'].tolist()\n",
        "\n",
        "    # Filter out products already rated by the user\n",
        "    products_to_predict = [p for p in unique_products if p not in user_rated_products]\n",
        "\n",
        "    # Predict ratings for each product\n",
        "    predictions = [\n",
        "        (product, model.predict(user_id, product).est)\n",
        "        for product in products_to_predict\n",
        "    ]\n",
        "\n",
        "    # Sort predictions by estimated rating (highest first)\n",
        "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Return the top recommendations\n",
        "    return predictions[:num_recommendations]\n",
        "\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    reviews_file_path = 'Reviews.csv'  # Replace with your reviews dataset file path\n",
        "    fixed_file_path = 'reviews_fixed.csv'  # Path to save the fixed CSV file\n",
        "    model_save_path = 'recommendation_model.pkl'  # Path to save the trained model\n",
        "\n",
        "    # Fix the CSV file\n",
        "    fix_csv(reviews_file_path, fixed_file_path)\n",
        "\n",
        "    # Load the fixed dataset\n",
        "    df_reviews = load_data(fixed_file_path)\n",
        "    data = prepare_data(df_reviews)\n",
        "\n",
        "    # Train and save the model\n",
        "    model = train_and_save_model(data, model_save_path)\n",
        "\n",
        "    # Generate recommendations for a user\n",
        "    user_id = 'A3SGXH7AUHU8GW'  # Replace with a valid user ID from your dataset\n",
        "    recommendations = recommend_products(model, user_id, df_reviews)\n",
        "\n",
        "    # Print recommendations\n",
        "    print(f\"Top recommendations for user {user_id}:\")\n",
        "    for i, (product_id, predicted_rating) in enumerate(recommendations, 1):\n",
        "        product_info = df_reviews[df_reviews['ProductId'] == product_id].iloc[0]\n",
        "        print(f\"{i}. Product ID: {product_id}, Predicted Rating: {predicted_rating:.2f}\")\n",
        "        print(f\"   Summary: {product_info['Summary']}\")\n",
        "        print(f\"   Text: {product_info['Text'][:100]}...\")  # Print first 100 characters of the review\n",
        "        print()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "from surprise import Dataset, Reader\n",
        "\n",
        "\n",
        "# Load dataset\n",
        "def load_data(file_path):\n",
        "    df = pd.read_csv(file_path, on_bad_lines='skip')  # Skip problematic rows\n",
        "    return df\n",
        "\n",
        "\n",
        "# Recommend products for a user using the saved model\n",
        "def recommend_products(model, user_id, df, num_recommendations=5):\n",
        "    # Get all unique products\n",
        "    unique_products = df['ProductId'].unique()\n",
        "\n",
        "    # Get products already rated by the user\n",
        "    user_rated_products = df[df['UserId'] == user_id]['ProductId'].tolist()\n",
        "\n",
        "    # Filter out products already rated by the user\n",
        "    products_to_predict = [p for p in unique_products if p not in user_rated_products]\n",
        "\n",
        "    # Predict ratings for each product\n",
        "    predictions = [\n",
        "        (product, model.predict(user_id, product).est)\n",
        "        for product in products_to_predict\n",
        "    ]\n",
        "\n",
        "    # Sort predictions by estimated rating (highest first)\n",
        "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Return the top recommendations\n",
        "    return predictions[:num_recommendations]\n",
        "\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # Paths\n",
        "    reviews_file_path = 'Reviews.csv'  # Path to the reviews dataset\n",
        "    model_path = 'recommendation_model.pkl'  # Path to the saved model\n",
        "\n",
        "    # Load the dataset\n",
        "    df_reviews = load_data(reviews_file_path)\n",
        "\n",
        "    # Load the trained model\n",
        "    model = joblib.load(model_path)\n",
        "    print(\"Model loaded successfully.\")\n",
        "\n",
        "    # Generate recommendations for a user\n",
        "    user_id = 'A3SGXH7AUHU8GW'  # Replace with a valid user ID from your dataset\n",
        "    recommendations = recommend_products(model, user_id, df_reviews)\n",
        "\n",
        "    # Print recommendations\n",
        "    print(f\"Top recommendations for user {user_id}:\")\n",
        "    for i, (product_id, predicted_rating) in enumerate(recommendations, 1):\n",
        "        product_info = df_reviews[df_reviews['ProductId'] == product_id].iloc[0]\n",
        "        print(f\"{i}. Product ID: {product_id}, Predicted Rating: {predicted_rating:.2f}\")\n",
        "        print(f\"   Summary: {product_info['Summary']}\")\n",
        "        print(f\"   Text: {product_info['Text'][:100]}...\")  # Print first 100 characters of the review\n",
        "        print()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_g3O7LPZaSM",
        "outputId": "6d954e54-c198-4e3e-d341-5e9854f05601"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully.\n",
            "Top recommendations for user A3SGXH7AUHU8GW:\n",
            "1. Product ID: B0032RPLSY, Predicted Rating: 5.00\n",
            "   Summary: Simply delicious flavor!\n",
            "   Text: I have been using butter ghee for cooking purposes, and found this product on Amazon.  The color is ...\n",
            "\n",
            "2. Product ID: B005EL6VOY, Predicted Rating: 5.00\n",
            "   Summary: Tasty and healthy!!\n",
            "   Text: My husband and I love Coach's Oats.  We first tried them on recommendation by a friend.  They are ki...\n",
            "\n",
            "3. Product ID: B0007UQ73W, Predicted Rating: 5.00\n",
            "   Summary: Staple item in my pantry\n",
            "   Text: I am a professional chef and work on mega yachts all around the world. This is one of the finest aut...\n",
            "\n",
            "4. Product ID: B000Q0IMOK, Predicted Rating: 5.00\n",
            "   Summary: Quality Product...good value\n",
            "   Text: This Chocolate can be found at Dean & DeLuca at twice the price.<br />The packaging is a plain plast...\n",
            "\n",
            "5. Product ID: B00401OZ1U, Predicted Rating: 5.00\n",
            "   Summary: Great pure taste\n",
            "   Text: No sugary junk here. Pure water and mint, nothing else, SPLENDID! If you are used to drinking sodas ...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bReT-fENZfDv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}